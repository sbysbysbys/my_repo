安装新浪财经客户端第一时间接收最全面的市场资讯→【下载地址】
　　新浪科技讯 北京时间7月6日早间消息，当地时间周三，ChatGPT的开发者OpenAI表示计划投入更多资源并成立新的研究团队，研究如何确保AI对人类的安全性，最终实现用AI来监督AI。
　　OpenAI联合创始人伊利亚·苏茨凯弗（Ilya Sutskever）和AI对齐负责人简·莱克（Jan Leike）在官方博客中表示：“超级智能的巨大能力可能导致人类失去力量甚至灭绝。目前，我们还没有解决方案来操纵或控制一个可能的超智能AI，并防止其变成无赖。”
　　这篇博文预测，超智能AI，即相比于人类更智能的系统，可能会在未来10年中出现。人类需要比目前更强大的技术来控制超智能AI，因此需要在“AI对齐研究”方面取得突破，确保人AI对人类持续有益。AI对齐是AI控制中的主要问题，即要求AI的目标和人类的价值观与意图保持一致。
　　作者写道，OpenAI将在未来4年内，将算力的20%专门用于解决这方面问题。此外，该公司将组建新的“超对齐”团队来组织这方面的工作。
　　该团队的目标是开发达到“人类水平”，由AI驱动的对齐研究员，随后通过庞大的算力推动其发展。OpenAI表示，这意味着将使用人工反馈来训练AI系统，通过训练AI系统来协助人工评估，最终训练AI系统来进行实际的对齐研究。
　　不过，人工智能安全的倡导者康纳·莱希（Connor Leahy）表示，OpenAI的计划存在根本性缺陷，因为最初的人类水平AI可能会失控并造成严重破坏，而这将迫使研究者去解决AI安全问题。他在接受采访时表示：“在构建人类水平的智能之前，必须先解决对齐问题，否则默认情况下你无法控制它。我个人认为这不是个特别好的、安全的计划。”
　　AI的潜在危险一直是AI研究员和公众最关心的问题。今年4月，一群AI行业领袖和专家签署公开信，呼吁暂停6个月开发比OpenAI的GPT-4更强大的系统，原因是对社会存在潜在风险。益普索今年5月的调查发现，超过2/3的美国人担心AI可能产生的负面影响，61%的人认为AI可能威胁人类文明。
责任编辑：刘明亮 
24小时滚动播报最新的财经资讯和视频，更多粉丝福利扫描二维码关注（sinafinance）
新浪财经意见反馈留言板
